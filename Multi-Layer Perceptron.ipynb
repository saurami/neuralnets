{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture of EMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/saurabh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import callbacks\n",
    "from keras import regularizers\n",
    "from scipy import io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 26\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below, the EMINST dataset is loaded and assigned as to variables which indicate training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('emnist-letters.mat')\n",
    "data = mat['dataset']\n",
    "x_train = data['train'][0,0]['images'][0,0]\n",
    "y_train = data['train'][0,0]['labels'][0,0]\n",
    "x_test = data['test'][0,0]['images'][0,0]\n",
    "y_test = data['test'][0,0]['labels'][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is reshaped to 1-dimensional 784 array, converted to 'float32' precision, and divided by the maximum value of a byte to ensure that the input features are scaled between 0.0 and 1.0.\n",
    "This ensures that the default learning rate (and other hyperparameters) work reasonably well, and the cost can take reasonable (unscaled) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(124800, 784)\n",
    "x_test = x_test.reshape(20800, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a class vector (of integers) to a binary class matrix, which has the same number of columns as the classes. Number of rows stays the same. Output is used with the categorical crossentropy loss function ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes+1)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and validation sets after binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_start = x_train.shape[0] - x_test.shape[0]\n",
    "x_val = x_train[val_start:x_train.shape[0],:]\n",
    "y_val = y_train[val_start:x_train.shape[0]]\n",
    "x_train = x_train[0:val_start,:]\n",
    "y_train = y_train[0:val_start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping parameters:-\n",
    "+ `monitor` will end training upon validation loss (given by 'val_loss'); when performance measure stops improving\n",
    "+ `mode` is automatically inferred from the name of the monitored quantity (given by 'monitor'); It is min for 'val_loss', max for 'val_acc'\n",
    "+ `verbose` will show the epoch in which training stopped\n",
    "+ `patience` is the number of epochs in which there should be improvement\n",
    "+ `min_delta` specifies improvement that is a specific increment\n",
    "+ `baseline` is the value the monitored quantity has to reach; Training will stop if the model doesn't show improvement over the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                         mode='auto', \n",
    "                                         verbose=1,\n",
    "                                         patience=5, \n",
    "                                         min_delta=0.05, \n",
    "                                         baseline=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear stack of three layers - one input layer, one hidden layer, and one output layer.\n",
    "In the hidden layer L2 regularization is used with 2048 neurons. (Comparison done in the **Observation** section below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2048, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes+1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 27)                55323     \n",
      "=================================================================\n",
      "Total params: 1,507,867\n",
      "Trainable params: 1,507,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/saurabh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 104000 samples, validate on 20800 samples\n",
      "Epoch 1/20\n",
      "104000/104000 [==============================] - 25s 240us/step - loss: 0.9582 - accuracy: 0.7838 - val_loss: 0.6114 - val_accuracy: 0.8564\n",
      "Epoch 2/20\n",
      "104000/104000 [==============================] - 25s 239us/step - loss: 0.5651 - accuracy: 0.8647 - val_loss: 0.5324 - val_accuracy: 0.8704\n",
      "Epoch 3/20\n",
      "104000/104000 [==============================] - 24s 230us/step - loss: 0.5058 - accuracy: 0.8807 - val_loss: 0.5226 - val_accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "104000/104000 [==============================] - 23s 217us/step - loss: 0.4737 - accuracy: 0.8875 - val_loss: 0.4662 - val_accuracy: 0.8938\n",
      "Epoch 5/20\n",
      "104000/104000 [==============================] - 22s 210us/step - loss: 0.4501 - accuracy: 0.8941 - val_loss: 0.4495 - val_accuracy: 0.8989\n",
      "Epoch 6/20\n",
      "104000/104000 [==============================] - 23s 221us/step - loss: 0.4299 - accuracy: 0.8980 - val_loss: 0.4391 - val_accuracy: 0.8990\n",
      "Epoch 7/20\n",
      "104000/104000 [==============================] - 24s 230us/step - loss: 0.4123 - accuracy: 0.9018 - val_loss: 0.4260 - val_accuracy: 0.9061\n",
      "Epoch 8/20\n",
      "104000/104000 [==============================] - 22s 216us/step - loss: 0.4007 - accuracy: 0.9051 - val_loss: 0.4244 - val_accuracy: 0.9041\n",
      "Epoch 9/20\n",
      "104000/104000 [==============================] - 26s 254us/step - loss: 0.3852 - accuracy: 0.9076 - val_loss: 0.4096 - val_accuracy: 0.9080\n",
      "Epoch 10/20\n",
      "104000/104000 [==============================] - 24s 233us/step - loss: 0.3758 - accuracy: 0.9108 - val_loss: 0.4004 - val_accuracy: 0.9111\n",
      "Epoch 11/20\n",
      "104000/104000 [==============================] - 25s 245us/step - loss: 0.3666 - accuracy: 0.9122 - val_loss: 0.4158 - val_accuracy: 0.9056\n",
      "Epoch 12/20\n",
      "104000/104000 [==============================] - 27s 264us/step - loss: 0.3572 - accuracy: 0.9140 - val_loss: 0.4294 - val_accuracy: 0.9051\n",
      "Epoch 13/20\n",
      "104000/104000 [==============================] - 23s 224us/step - loss: 0.3518 - accuracy: 0.9148 - val_loss: 0.4213 - val_accuracy: 0.9063\n",
      "Epoch 14/20\n",
      "104000/104000 [==============================] - 23s 225us/step - loss: 0.3458 - accuracy: 0.9163 - val_loss: 0.4128 - val_accuracy: 0.9096\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4151294681659112\n",
      "Test accuracy: 0.9102884531021118\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Running `mnist_mlp.py` produces an accuracy ranging from `98.2` to `98.4`, which is very close to the accuracy given on the github repository. \n",
    "\n",
    "+ Highest accuracy using the validation set was obtained with ReLU activation - marginally above 90%. (Validation set was used to run the program multiple times for verification.)\n",
    "\n",
    "+ Fitting validation sets in the model's `validation_data`:\n",
    "\n",
    "| Hidden Layer Activation | Accuracy | Loss | Epochs\n",
    "| --- | --- | --- | --- |\n",
    "| ReLU | 90.53% | 42.06% | 9 (early stopping)\n",
    "| Softmax | 85.28% | 74.45% | 20\n",
    "| tanh | 89.95% | 41.35% | 10 (early stopping)\n",
    "| Sigmoid | 90.31% | 41.09% | 16 (early stopping)\n",
    "\n",
    "+ Fitting test sets in the model's `validation_data`:\n",
    "\n",
    "| Hidden Layer Activation | Accuracy | Loss | Epochs\n",
    "| --- | --- | --- | --- |\n",
    "| ReLU | 90.08% | 44.09% | 11 (early stopping)\n",
    "| Softmax | 85.78% | 75.24% | 20\n",
    "| tanh | 90.20% | 39.34% | 13 (early stopping)\n",
    "| Sigmoid | 89.82% | 42.75% | 13 (early stopping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
